This new technology of studying emotions via computer can be exploited due to faking faces. When Eckman said that he classified 6 emotions and gave the example of what controls what, the problem arises as in that it maybe false information due to a blank type of facial features that are unreadable. Also, if the person is capabale, they can hide their emotions by faking a different facial feature to put forth a positive type of vibe in such a way machines cant read. This is most likely going to backfire and have mis information due to errors and exploits. Emotions arent an algorith, they reflect us as a human and shouldnt be exploited to some company to make some big bucks.

The human is a complex entity to study because we are adapting over time so much, we change on a daily basis and thats what is the issue, if we were all like minded, then it would make sense a robot can understand us. This new technology of studying human emotions, isnt going to get us anywhere.