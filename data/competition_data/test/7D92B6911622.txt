"Driverless cars"? What are "driverless cars"? "Driverless cars" are cars that are programmed to drive without a driver. It can cruise, turn, stop, go without a actual driver. What would happen if this type of car got in a accident? Who are to blame? As said in the article, "who is at fault, the driver or the manufacturer?" This type of problem would cause a lot of trouble. Should we be for or against "driverless cars?"

A "driverless car" is only programmed to do the basic driving needs. For example, speed up, slow down, stop, go, turn, reverse, and more. "Driverless cars" don't have common sense. What if there is a cat that is crossing the road and the car dosen't sense it. The cat would just die, if a human was driving the car he/she would see it and stop immedietly. The car dosen't have that mentality. As said in the passage " all are designed to notify the driver when the road ahead requires human skills." This proves that the "driverless cars" can't handle every situation and are at great risk of causing a accident. The passage said, "Why would anyone want a driverless car that still needs a driver?"

What would happen if this "driverless car" got into a accident? As I metioned earlier, who is there to blame? The manufacturer or the owner of the car. Since the "driverless cars" can't drive in complex roads and need to notify the human to drive, what would happen if they aren't notified in time? It would cause a accident. This would start a argument between the owner of the car and the manufacturer. The owner of the car would want to sue the manufactuer for selling him/her a bad machine. Most of the people that purchased the "driverless cars" would want to blame the manufaturer even if it was their fault, just to get out of trouble.

Everyday machine like microwaves, televisons, phones, and refrigerators malfunctions all the time. They are machines they are not perfect and cannot last forever. They could crash at anytime. This "driverless car" is a machine, it can malfunction at any random time, just like any other machine. For example, if I had a "driverless car" and there was a stop light but the car didn't stop, what would happen? There would be another accident. You can't trust machines like you can trust an actual human being. A human being has control over the driving and knows exactly what to do, unlike a "driverless car." You can't even trust a "driverless car" to take you to your location. It might malfunction and get you lost. Then again, who is there to blame? The manufacturer or the owner of the vehicle?

I think that "driverless cars" are not good for humanity. They have their benefits but, not enough. It would come with too many accidents and problems. The manufacturer would get sued and the buyer would be furious. I am against these "driverless cars." Maybe in the far future when technology has reached its highest and there is almost no doubt it would fail. 