Today, technology in classrooms is huge. Almost all classrooms use technology nearly everyday. However, not everyone of them is effective because they are easier to slack off on without having a human to tell them to continue on even after they are bored, tired and even confused. Dr. Thomas Huang decided to create a system to help with this problem. He made a system called FACS or Facial Action Coding System. This system on a computer, reads emotions that on displayed on peoples face.

There are 44 major muscles in the human face. Each one of these muscles helps researchers find new ways to read emotions. Dr. Thomas Huang is one of these researchers. Dr. Huang says, "The facial expressions for each emotion are universal,". He means by this that because there are so many different muscles in your face, and them all being able to show different emotions, there is an endless amount of expressions to be made. For example, you can probabaly read your friends face and see what kind of day they are having by reading the emotion on their face. Unlike the smart Facial Action Coding System, we are not able to completely describe each facial trait showed by our friend, although we can still tell their state of emotion. For example when using FACS, researchers were able to tell that Leonardo da Vinci's Renaissance painting, Mona Lisa was 83% happy, 9% disgusted, 6% fearful and 2% angry.

It is thought that the Facial Action Coding System (FACS) could help students better in the classrom. "A classroom computer could recognize when a student is becoming confused or bored," Dr Haung predicted. He also stated that if the FACS could recognize taht on students faces, it could also modify the lesson, like an effective human instructor would. Dr. Huang also states "Most human communication is nonverball, including emotional communication,". Even though this system could prove to be effective, not all students are only learning on computers and are learning verbally from a teacher. A teacher is unable to identify the exact percent of each emotion you feel but can still read your emotions just as your friend would.

Nick D'Alto, the author of Making Mona Lisa Smile, gives us an example of demonstration we could try. "While looking in the mirror: 1. Raise your lips at the corners of your mouth. 2. Then squint your eyes slightly, to produce wrinkling ('crow's-feet") at the corners of your eyes. 3. Holding that, raise the outer parts of your cheeks up, toward your eyes.". By having a partner guess which emotion your are portraying, he is doing as the FACS would. Your partner probabaly would have guessed happy. The computers would have been able to tell that you are feeling happy, and continue on with your work. However, if you were to have been looking confused, the computer would stop, and try to help explain the problem to you.

The computers could very easily help in the classrooms to make students work to the best of their ability. By being able to read emotions, the computers will make it harder for students to slack off while previoulsy it would have been moderatly easy. Humans perform these face "calculations" everyday without realizing it. Now the FACS system can join along with us and then some by creating a better work environemnt for the students. 